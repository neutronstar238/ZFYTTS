# æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹

åŸºäºåº„æ–¹å®œæ¨¡å‹çš„ LLM å¯¹è¯ + TTS è¯­éŸ³åˆæˆç³»ç»Ÿã€‚

---

## é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ LLMchat/                    # LLM èŠå¤©æ¨¡å—
â”‚   â”œâ”€â”€ chat_api.py             # REST API æœåŠ¡
â”‚   â”œâ”€â”€ chat_manager.py         # æ ¸å¿ƒç®¡ç†å™¨
â”‚   â””â”€â”€ zhuang_fangyi_int4.gguf # LLM æ¨¡å‹
â”‚
â”œâ”€â”€ text_to_speech/             # TTS è¯­éŸ³åˆæˆæ¨¡å—
â”‚   â”œâ”€â”€ tts_api.py              # REST API æœåŠ¡
â”‚   â”œâ”€â”€ simple_tts.py           # TTS æ ¸å¿ƒå®ç°
â”‚   â”œâ”€â”€ GPT_weights_v2/         # GPT æ¨¡å‹æƒé‡
â”‚   â””â”€â”€ SoVITS_weights_v2/      # SoVITS æ¨¡å‹æƒé‡
â”‚
â”œâ”€â”€ API_DOCUMENTATION.md        # å®Œæ•´ API æ¥å£æ–‡æ¡£
â”œâ”€â”€ requirements.txt            # é¡¹ç›®ä¾èµ–
â”œâ”€â”€ test_apis.py                # API æµ‹è¯•è„šæœ¬
â””â”€â”€ integration_example.py      # é›†æˆä½¿ç”¨ç¤ºä¾‹
```

---

## å¿«é€Ÿå¼€å§‹

### 0. å‡†å¤‡æ¨¡å‹æ–‡ä»¶

**âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸åŒ…å«åœ¨ä»“åº“ä¸­ï¼Œéœ€è¦å•ç‹¬ä¸‹è½½å¹¶æ”¾ç½®åˆ°æŒ‡å®šä½ç½®ã€‚**

#### LLM æ¨¡å‹æ–‡ä»¶

```
LLMchat/zhuang_fangyi_int4.gguf    # çº¦ 2-4 GB
```

#### TTS æ¨¡å‹æ–‡ä»¶

**å¾®è°ƒæ¨¡å‹ï¼ˆå¿…éœ€ï¼‰:**
```
text_to_speech/GPT_weights_v2/ZhuangFangyi_V1-e16.ckpt          # çº¦ 500 MB
text_to_speech/SoVITS_weights_v2/ZhuangFangyi_V1_e20_s300.pth   # çº¦ 300 MB
text_to_speech/logs/ZhuangFangyi_V1/reference_audio/
    â””â”€â”€ zfy_raw_vocals.wav_0011840000_0012000960.wav            # çº¦ 1 MB
```

**åŸºç¡€é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¿…éœ€ï¼‰:**
```
text_to_speech/GPT_SoVITS/pretrained_models/
â”œâ”€â”€ chinese-hubert-base/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ preprocessor_config.json
â”‚   â””â”€â”€ pytorch_model.bin                                       # çº¦ 400 MB
â”œâ”€â”€ chinese-roberta-wwm-ext-large/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin                                       # çº¦ 1.2 GB
â”‚   â””â”€â”€ tokenizer.json
â”œâ”€â”€ g2pw-chinese/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin                                       # çº¦ 400 MB
â”‚   â””â”€â”€ [å…¶ä»–é…ç½®æ–‡ä»¶]
â”œâ”€â”€ models--nvidia--bigvgan_v2_24khz_100band_256x/
â”‚   â”œâ”€â”€ bigvgan_generator.pt                                    # çº¦ 350 MB
â”‚   â””â”€â”€ config.json
â”œâ”€â”€ v2Pro/
â”‚   â”œâ”€â”€ s2Gv2Pro.pth                                           # çº¦ 600 MB
â”‚   â””â”€â”€ s2Dv2Pro.pth                                           # çº¦ 300 MB
â”œâ”€â”€ sv/
â”‚   â””â”€â”€ pretrained_eres2netv2w24s4ep4.ckpt                     # çº¦ 200 MB
â”œâ”€â”€ fast_langdetect/
â”‚   â””â”€â”€ lid.176.bin                                            # çº¦ 1 MB
â”œâ”€â”€ s1v3.ckpt                                                  # çº¦ 500 MB
â”œâ”€â”€ s2Gv3.pth                                                  # çº¦ 600 MB
â””â”€â”€ [å…¶ä»–åŸºç¡€æ¨¡å‹æ–‡ä»¶]
```

**æ€»è®¡å¤§å°:** çº¦ 8-10 GBï¼ˆåŒ…å«æ‰€æœ‰æ¨¡å‹ï¼‰

**éªŒè¯æ¨¡å‹æ–‡ä»¶:**
```bash
# Windows
dir LLMchat\zhuang_fangyi_int4.gguf
dir text_to_speech\GPT_weights_v2\ZhuangFangyi_V1-e16.ckpt
dir text_to_speech\GPT_SoVITS\pretrained_models\chinese-hubert-base\pytorch_model.bin

# Linux/Mac
ls -lh LLMchat/zhuang_fangyi_int4.gguf
ls -lh text_to_speech/GPT_weights_v2/ZhuangFangyi_V1-e16.ckpt
ls -lh text_to_speech/GPT_SoVITS/pretrained_models/chinese-hubert-base/pytorch_model.bin
```

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

**æ³¨æ„:** é»˜è®¤å®‰è£… CPU ç‰ˆæœ¬ã€‚GPU ç‰ˆæœ¬å®‰è£…è§ä¸‹æ–¹ "GPU/CPU é…ç½®" éƒ¨åˆ†ã€‚

### 2. å¯åŠ¨æœåŠ¡

**ç»ˆç«¯ 1 - LLM Chat API:**
```bash
cd LLMchat
python chat_api.py
```

**ç»ˆç«¯ 2 - TTS API:**
```bash
cd text_to_speech
python tts_api.py
```

### 3. æµ‹è¯•

```bash
python test_apis.py
```

---

## API æœåŠ¡

### LLM Chat API (ç«¯å£ 5000)

æ™ºèƒ½å¯¹è¯æœåŠ¡ï¼Œæ”¯æŒå¤šç”¨æˆ·ã€å¤šä¼šè¯ç®¡ç†ã€‚

**ä¸»è¦ç«¯ç‚¹:**
- `POST /api/chat` - å‘é€æ¶ˆæ¯
- `GET /api/sessions/<user_id>` - è·å–ä¼šè¯åˆ—è¡¨
- `GET /api/health` - å¥åº·æ£€æŸ¥

**ç¤ºä¾‹:**
```python
import requests

response = requests.post(
    "http://localhost:5000/api/chat",
    json={"message": "ä½ å¥½", "user_id": "user_001"},
    timeout=180
)
print(response.json()['data']['response'])
```

### TTS API (ç«¯å£ 5001)

æ–‡å­—è½¬è¯­éŸ³æœåŠ¡ã€‚

**ä¸»è¦ç«¯ç‚¹:**
- `POST /api/tts/generate` - ç”Ÿæˆè¯­éŸ³
- `POST /api/tts/batch` - æ‰¹é‡ç”Ÿæˆ
- `GET /api/tts/audio/<filename>` - è·å–éŸ³é¢‘æ–‡ä»¶
- `GET /api/tts/health` - å¥åº·æ£€æŸ¥

**ç¤ºä¾‹:**
```python
import requests

response = requests.post(
    "http://localhost:5001/api/tts/generate",
    json={"text": "ä½ å¥½ï¼Œè¿™æ˜¯æµ‹è¯•", "speed": 1.0}
)
print(response.json()['data']['audio_url'])
```

**å®Œæ•´ API æ–‡æ¡£:** [API_DOCUMENTATION.md](API_DOCUMENTATION.md)

---

## GPU/CPU é…ç½®

ä¸¤ä¸ªæœåŠ¡é»˜è®¤ä½¿ç”¨ GPU åŠ é€Ÿã€‚å¦‚éœ€ä½¿ç”¨ CPUï¼Œä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š

### LLM Chat API

ç¼–è¾‘ `LLMchat/chat_api.py`:
```python
USE_GPU = False  # æ”¹ä¸º False ä½¿ç”¨ CPU
N_GPU_LAYERS = 0
```

### TTS API

ç¼–è¾‘ `text_to_speech/tts_api.py`:
```python
USE_GPU = False  # æ”¹ä¸º False ä½¿ç”¨ CPU
USE_HALF_PRECISION = False
```

**æ€§èƒ½å¯¹æ¯”:**

| æœåŠ¡ | GPU æ¨¡å¼ | CPU æ¨¡å¼ |
|------|---------|---------|
| LLM Chat | 5-15ç§’ | 30-120ç§’ |
| TTS | 2-4ç§’ | 5-10ç§’ |

**GPU è¦æ±‚:**
- NVIDIA GPU with CUDA 11.8+
- æ˜¾å­˜: 4GB+ (æ¨è 6GB+)

**å®‰è£… GPU ç‰ˆæœ¬ PyTorch:**
```bash
pip uninstall torch torchaudio
pip install torch==2.9.1+cu130 torchaudio==2.9.1 --extra-index-url https://download.pytorch.org/whl/nightly/cu130
```

---

## é›†æˆä½¿ç”¨

å®Œæ•´ç¤ºä¾‹è§ `integration_example.py`ï¼š

```python
import requests

# 1. LLM å¯¹è¯
chat_response = requests.post(
    "http://localhost:5000/api/chat",
    json={"message": "ç»™æˆ‘è®²ä¸ªç¬‘è¯", "user_id": "user_001"},
    timeout=180
)
text_reply = chat_response.json()['data']['response']

# 2. è½¬ä¸ºè¯­éŸ³
tts_response = requests.post(
    "http://localhost:5001/api/tts/generate",
    json={"text": text_reply[:50], "speed": 1.0}
)
audio_url = tts_response.json()['data']['audio_url']
print(f"éŸ³é¢‘: http://localhost:5001{audio_url}")
```

---

## å¸¸è§é—®é¢˜

### Q: LLM å“åº”å¾ˆæ…¢ï¼Ÿ
A: ä½¿ç”¨ CPU æ¨¡å¼æ—¶å“åº”æ—¶é—´ä¸º 30-120 ç§’ï¼Œè¿™æ˜¯æ­£å¸¸çš„ã€‚å»ºè®®ï¼š
- å¯ç”¨ GPU åŠ é€Ÿï¼ˆå“åº”æ—¶é—´é™è‡³ 5-15 ç§’ï¼‰
- å¢åŠ è¶…æ—¶æ—¶é—´åˆ° 180 ç§’ä»¥ä¸Š

### Q: å¦‚ä½•éªŒè¯ GPU æ˜¯å¦å¯ç”¨ï¼Ÿ
A: æŸ¥çœ‹æœåŠ¡å¯åŠ¨æ—¥å¿—ï¼š
```
# LLM Chat API
ğŸš€ GPU åŠ é€Ÿå·²å¯ç”¨ (offloading 35 layers)

# TTS API
TTS API é…ç½®:
  GPU åŠ é€Ÿ: âœ… å¯ç”¨
  åŠç²¾åº¦: âœ… å¯ç”¨
```

### Q: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
A: 
- LLM: å‡å°‘ `N_GPU_LAYERS` (å¦‚æ”¹ä¸º 20)
- TTS: è®¾ç½® `USE_HALF_PRECISION = False`
- æˆ–ä½¿ç”¨ CPU æ¨¡å¼

### Q: å¦‚ä½•ç®¡ç†å¤šä¸ªç”¨æˆ·ï¼Ÿ
A: æ¯ä¸ªç”¨æˆ·ä½¿ç”¨å”¯ä¸€çš„ `user_id`ï¼Œç³»ç»Ÿè‡ªåŠ¨éš”ç¦»æ•°æ®ï¼š
```python
# ç”¨æˆ·1
requests.post("http://localhost:5000/api/chat", 
    json={"message": "ä½ å¥½", "user_id": "user_001"})

# ç”¨æˆ·2
requests.post("http://localhost:5000/api/chat", 
    json={"message": "ä½ å¥½", "user_id": "user_002"})
```

### Q: æ¨¡å‹æ–‡ä»¶æ”¾åœ¨å“ªé‡Œï¼Ÿ
A: 
**LLM æ¨¡å‹:**
- `LLMchat/zhuang_fangyi_int4.gguf`

**TTS å¾®è°ƒæ¨¡å‹:**
- `text_to_speech/GPT_weights_v2/ZhuangFangyi_V1-e16.ckpt`
- `text_to_speech/SoVITS_weights_v2/ZhuangFangyi_V1_e20_s300.pth`

**TTS åŸºç¡€æ¨¡å‹:**
- `text_to_speech/GPT_SoVITS/pretrained_models/` ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶

æ–‡ä»¶åå’Œè·¯å¾„å¿…é¡»å®Œå…¨åŒ¹é…ï¼Œè·¯å¾„åŒºåˆ†å¤§å°å†™ã€‚æ€»è®¡çº¦ 8-10 GBã€‚

---

## ç³»ç»Ÿè¦æ±‚

- Python 3.9+
- CPU: 4æ ¸ä»¥ä¸Š
- å†…å­˜: 8GB+ (CPUæ¨¡å¼) / 4GB+ (GPUæ¨¡å¼)
- æ˜¾å­˜: 4GB+ (GPUæ¨¡å¼)
- ç£ç›˜: 10GB+

---

## ç”Ÿäº§éƒ¨ç½²

ä½¿ç”¨ Gunicorn:

```bash
# LLM Chat API
cd LLMchat
gunicorn -w 4 -b 0.0.0.0:5000 chat_api:app --timeout 180

# TTS API
cd text_to_speech
gunicorn -w 2 -b 0.0.0.0:5001 tts_api:app --timeout 120
```

---

## æ–‡ä»¶è¯´æ˜

- `API_DOCUMENTATION.md` - å®Œæ•´ API æ¥å£æ–‡æ¡£
- `requirements.txt` - é¡¹ç›®ä¾èµ–åˆ—è¡¨
- `test_apis.py` - API æµ‹è¯•è„šæœ¬
- `integration_example.py` - LLM + TTS é›†æˆç¤ºä¾‹

---

## æŠ€æœ¯æ ˆ

- **LLM**: llama-cpp-python (INT4 é‡åŒ–æ¨¡å‹)
- **TTS**: GPT-SoVITS (v2Pro)
- **Web æ¡†æ¶**: Flask
- **æ·±åº¦å­¦ä¹ **: PyTorch

---

## è®¸å¯è¯

è¯·å‚è€ƒå„å­é¡¹ç›®çš„è®¸å¯è¯æ–‡ä»¶ã€‚

---

## æ›´æ–°æ—¥å¿—

### v1.0 (2026-02-12)
- âœ… LLM Chat API å®Œæ•´åŠŸèƒ½
- âœ… TTS API å®Œæ•´åŠŸèƒ½
- âœ… å¤šç”¨æˆ·ã€å¤šä¼šè¯æ”¯æŒ
- âœ… GPU/CPU é…ç½®æ”¯æŒ
- âœ… å®Œæ•´ API æ–‡æ¡£

---

**å¿«é€Ÿé“¾æ¥:**
- [API æ–‡æ¡£](API_DOCUMENTATION.md)
- [æµ‹è¯•è„šæœ¬](test_apis.py)
- [é›†æˆç¤ºä¾‹](integration_example.py)
